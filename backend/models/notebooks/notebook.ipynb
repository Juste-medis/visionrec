{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Scikit-learn imports\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Other imports\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# TensorFlow and Keras imports\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Other imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image  # For displaying images in Jupyter notebooks\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why waste classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display image\n",
    "Image(r'D:Content\\share-of-global-mismanaged-plastic-waste.png', width=900, height=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display image\n",
    "Image(r'D:Content\\stats e waste.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display image\n",
    "Image(r'D:Content\\waste crisis.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display image\n",
    "Image(r'D:Content\\sorting challenges.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waste Sorting is Risky and Time-Intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display image\n",
    "Image(r'D:Content\\wastesorting.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose:   \n",
    "**Effiecient Deep Learning Model That Classifies Images as Organic or Recyclable**\n",
    "# Data Structure\n",
    "Data source: https://www.kaggle.com/datasets/wasifmahmood01/custom-waste-classification-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display image\n",
    "Image(r'D:Content\\Dataset (4).png', width=900, height=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base directory for the dataset\n",
    "BASE_DIR = r\"C:\\Users\\Hp\\pictures\\back up\\wastes\"  # Change this to the path where your dataset is located\n",
    "\n",
    "# Define the paths to the training and test directories\n",
    "train_dir = os.path.join(BASE_DIR, 'train')  # Path to the training data\n",
    "test_dir = os.path.join(BASE_DIR, 'test')    # Path to the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training directory path\n",
    "train_dir = r\"C:\\Users\\Hp\\pictures\\back up\\wastes\\train\"  # Replace with your actual training folder path\n",
    "\n",
    "# List all the class names in your training dataset\n",
    "class_names = os.listdir(train_dir)\n",
    "\n",
    "# Visualize and count the number of images in each class for training data\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    class_images = glob.glob(os.path.join(class_dir, '*.jpg'))  # Assuming .jpg files\n",
    "    print(f\"Number of training samples in class '{class_name}': {len(class_images)}\")\n",
    "\n",
    "    # Visualizing some random images from each class (to get a sense of the data)\n",
    "    if len(class_images) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i in range(5):  # Displaying 5 random images from this class\n",
    "            plt.subplot(1, 5, i+1)\n",
    "            img_path = np.random.choice(class_images)  # Randomly choose an image\n",
    "            img = load_img(img_path, target_size=(224, 224))  # Load and resize image\n",
    "            img_array = img_to_array(img) / 255.0  # Convert to array and normalize\n",
    "            plt.imshow(img_array)\n",
    "            plt.axis('off')\n",
    "            plt.title(class_name)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your test directory path\n",
    "test_dir = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\test\"  # Replace with your actual test folder path\n",
    "IMG_SIZE = (224, 224)\n",
    "# List all the class names in your test dataset\n",
    "class_names = os.listdir(test_dir)\n",
    "\n",
    "# Visualize and count the number of images in each class for test data\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(test_dir, class_name)\n",
    "    class_images = glob.glob(os.path.join(class_dir, '*.jpg'))  # Assuming .jpg files\n",
    "    print(f\"Number of test samples in class '{class_name}': {len(class_images)}\")\n",
    "\n",
    "    # Visualizing some random images from each class (to get a sense of the data)\n",
    "    if len(class_images) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i in range(5):  # Displaying 5 random images from this class\n",
    "            plt.subplot(1, 5, i+1)\n",
    "            img_path = np.random.choice(class_images)  # Randomly choose an image\n",
    "            img = load_img(img_path, target_size=(IMG_SIZE))  # Load and resize image\n",
    "            img_array = img_to_array(img) / 255.0  # Convert to array and normalize\n",
    "            plt.imshow(img_array)\n",
    "            plt.axis('off')\n",
    "            plt.title(class_name)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **Data Augmentation**\n",
    "\n",
    "Data Augmentation is a technique that helps to increase the diversity of your training data without actually collecting new data. It artificially expands the size of the training dataset by applying random transformations to the images. This helps the model generalize better and reduces overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **Here are the transformations we will apply to the training data:**\n",
    "\n",
    "### 1. **Rotation:** \n",
    "   - Random rotation of images by a certain degree.\n",
    "\n",
    "### 2. **Shifting:** \n",
    "   - Random horizontal and vertical shifts.\n",
    "\n",
    "### 3. **Shear:** \n",
    "   - Shear transformations that make the images slanted.\n",
    "\n",
    "### 4. **Zoom:** \n",
    "   - Zooming into the image by a random factor.\n",
    "\n",
    "### 5. **Flipping:** \n",
    "   - Horizontal flipping of the images.\n",
    "\n",
    "### 6. **Rescaling:** \n",
    "   - Normalize the image pixel values to [0, 1] to make them consistent with the pretrained model inputs.\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Augmentation for Training Set:**\n",
    "\n",
    "The training data will undergo multiple random transformations to increase the diversity of the dataset.\n",
    "\n",
    "### 1. **Rotation Range:** \n",
    "   - Rotate images by up to 30 degrees.\n",
    "\n",
    "### 2. **Width and Height Shift:** \n",
    "   - Shift the images horizontally and vertically by up to 20%.\n",
    "\n",
    "### 3. **Zoom Range:** \n",
    "   - Zoom in and out by up to 20%.\n",
    "\n",
    "### 4. **Shear Range:** \n",
    "   - Apply shear transformations (slanting) up to 20%.\n",
    "\n",
    "### 5. **Horizontal Flip:** \n",
    "   - Randomly flip images horizontally.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for image size and batch size\n",
    "IMG_SIZE = (224, 224)  # Resize images to 224x224 (common for models like MobileNetV2)\n",
    "BATCH_SIZE = 32  # Define batch size for training and testing\n",
    "BASE_DIR = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\"  # Path to the dataset\n",
    "\n",
    "# Train data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize image pixel values to [0, 1]\n",
    "    rotation_range=30,  # Rotate images by up to 30 degrees\n",
    "    width_shift_range=0.2,  # Shift images horizontally by up to 20%\n",
    "    height_shift_range=0.2,  # Shift images vertically by up to 20%\n",
    "    shear_range=0.2,  # Apply shear transformations (slanting) up to 20%\n",
    "    zoom_range=0.2,  # Zoom in and out by up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill in missing pixels during transformations\n",
    ")\n",
    "\n",
    "# Test data generator (no augmentation, only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)  # Normalize image pixel values to [0, 1]\n",
    "\n",
    "# Training data generator using the training directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=os.path.join(BASE_DIR , 'train'),  # Path to training dataset\n",
    "    target_size=IMG_SIZE,  # Resize images to IMG_SIZE\n",
    "    batch_size=BATCH_SIZE,  # Batch size for training\n",
    "    class_mode='categorical'  # Multi-class classification\n",
    ")\n",
    "\n",
    "# Test data generator using the test directory\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=os.path.join(BASE_DIR , 'test'),  # Path to test dataset\n",
    "    target_size=IMG_SIZE,  # Resize images to IMG_SIZE\n",
    "    batch_size=BATCH_SIZE,  # Batch size for testing\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    shuffle=False  # Don't shuffle test data for evaluation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels from the training dataset\n",
    "class_labels = train_generator.class_indices  # returns a dictionary of class names and their indices\n",
    "\n",
    "# Print the class labels and their corresponding encoded values\n",
    "print(\"Class Labels and Encoded Values:\")\n",
    "print(class_labels)\n",
    "\n",
    "reversed_labels = {v: k for k, v in class_labels.items()}\n",
    "print(\"\\nReversed Encoded Labels:\")\n",
    "print(reversed_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the path for saving model weights\n",
    "filepath = './final_model_weights.keras'  # Change the extension to .keras\n",
    "\n",
    "# Early stopping callback: monitors the validation AUC (Area Under Curve)\n",
    "earlystopping = EarlyStopping(monitor='val_auc',  # Monitors validation AUC\n",
    "                              mode='max',         # Stops when the validation AUC does not improve\n",
    "                              patience=5,         # Patience is the number of epochs with no improvement before stopping\n",
    "                              verbose=1)          # Prints messages when stopping\n",
    "\n",
    "# Model checkpoint callback: saves the best model based on validation AUC\n",
    "checkpoint = ModelCheckpoint(filepath,            # Filepath to save the best model weights\n",
    "                              monitor='val_auc',  # Monitors validation AUC\n",
    "                              mode='max',         # Save the model with the highest AUC\n",
    "                              save_best_only=True,  # Only save the best model\n",
    "                              verbose=1)          # Prints messages when saving the model\n",
    "\n",
    "# List of callbacks to use during training\n",
    "callback_list = [earlystopping, checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Base model: MobileNetV2 pre-trained on ImageNet\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3),  # Adjust input size as per your requirements\n",
    "                          include_top=False,          # Exclude the top classification layers\n",
    "                          weights=\"imagenet\")         # Load pre-trained weights from ImageNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Load the pretrained MobileNetV2 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the base model layers\n",
    "\n",
    "# Redefining the model with reduced dense layer sizes\n",
    "model = Sequential()\n",
    "\n",
    "# Add the base model (MobileNetV2)\n",
    "model.add(base_model)\n",
    "\n",
    "# Add dropout and flatten layers\n",
    "model.add(Dropout(0.2))  # Dropout layer for regularization\n",
    "model.add(Flatten())  # Flatten the output of base model to feed into fully connected layers\n",
    "\n",
    "# Add batch normalization and dense layers with smaller sizes\n",
    "model.add(BatchNormalization())  # Normalize the output of previous layer\n",
    "model.add(Dense(512, activation=\"relu\", kernel_initializer='he_uniform'))  # First dense layer\n",
    "model.add(BatchNormalization())  # Another batch normalization layer\n",
    "model.add(Dropout(0.2))  # Dropout layer for regularization\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\", kernel_initializer='he_uniform'))  # Second dense layer\n",
    "model.add(BatchNormalization())  # Batch normalization\n",
    "model.add(Dropout(0.2))  # Dropout for regularization\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\", kernel_initializer='he_uniform'))  # Third dense layer\n",
    "model.add(Dropout(0.2))  # Dropout layer\n",
    "\n",
    "# Final output layer with 9 classes and softmax activation\n",
    "model.add(Dense(9, activation=\"softmax\"))  # Softmax activation for multi-class classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Your `PyDataset` class should call `super().__init__(**kwargs)`\")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),  # Adam optimizer with a small learning rate\n",
    "              loss='categorical_crossentropy',  # Using categorical crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])  # Metrics to track during training\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(\n",
    "    train_generator,  # The training data generator\n",
    "    epochs=15,  # Number of epochs\n",
    "    validation_data=test_generator,  # Validation data generator\n",
    "    callbacks=callback_list  # List of callbacks (early stopping and checkpoint)\n",
    ")\n",
    "\n",
    "\n",
    "# Saving the Final Model\n",
    "model.save(\"mobilenetv2_waste_classification_final.h5\")\n",
    "print(\"Final Model Saved as mobilenetv2_waste_classification_final.h5\")\n",
    "\n",
    "# Evaluating the Model on Test Data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")# Plot training performance\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Performance')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save(\"mobilenetv2_waste_classification.h5\")\n",
    "print(\"Model saved as mobilenetv2_waste_classification.h5\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "test_generator.reset()\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_classes, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional necessary libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Convert predictions to label indices\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true labels from the test_generator\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=test_generator.class_indices.keys(),\n",
    "            yticklabels=test_generator.class_indices.keys(), cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mobilenetv2_waste_classification.h5')\n",
    "\n",
    "# Set image size and path\n",
    "IMG_SIZE = (224, 224)  # Same as the model input size\n",
    "img_path = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\test\\E-waste\\E-waste (216).jpg\"  # Replace with the path to the image you want to predict\n",
    "\n",
    "# Preprocess the image\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)  # Load and resize the image\n",
    "img_array = image.img_to_array(img)  # Convert image to array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Rescale the image\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the index of the highest predicted class\n",
    "\n",
    "# Manually define the class labels (use the folder names in your dataset)\n",
    "# Replace this path with the actual path to your 'train' directory\n",
    "train_dir = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\train\"\n",
    "class_labels = sorted(os.listdir(train_dir))  # Sort to ensure consistent order\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mobilenetv2_waste_classification.h5')\n",
    "\n",
    "# Set image size and path\n",
    "IMG_SIZE = (224, 224)  # Same as the model input size\n",
    "img_path = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\test\\organic waste\\Organic waste (5).jpeg\"  # Replace with the path to the image you want to predict\n",
    "\n",
    "# Preprocess the image\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)  # Load and resize the image\n",
    "img_array = image.img_to_array(img)  # Convert image to array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Rescale the image\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the index of the highest predicted class\n",
    "\n",
    "# Manually define the class labels (use the folder names in your dataset)\n",
    "# Replace this path with the actual path to your 'train' directory\n",
    "train_dir = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\train\"\n",
    "class_labels = sorted(os.listdir(train_dir))  # Sort to ensure consistent order\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mobilenetv2_waste_classification.h5')\n",
    "\n",
    "# Set image size and path\n",
    "IMG_SIZE = (224, 224)  # Same as the model input size\n",
    "img_path = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\train\\automobile wastes\\automobile waste (20).jpg\"  # Replace with the path to the image you want to predict\n",
    "\n",
    "# Preprocess the image\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)  # Load and resize the image\n",
    "img_array = image.img_to_array(img)  # Convert image to array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Rescale the image\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the index of the highest predicted class\n",
    "\n",
    "# Manually define the class labels (use the folder names in your dataset)\n",
    "# Replace this path with the actual path to your 'train' directory\n",
    "train_dir = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\train\"\n",
    "class_labels = sorted(os.listdir(train_dir))  # Sort to ensure consistent order\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mobilenetv2_waste_classification.h5')\n",
    "\n",
    "# Set image size and path\n",
    "IMG_SIZE = (224, 224)  # Same as the model input size\n",
    "img_path = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\test\\paper waste\\IMG20250118011726.jpg\"  # Replace with the path to the image you want to predict\n",
    "\n",
    "# Preprocess the image\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)  # Load and resize the image\n",
    "img_array = image.img_to_array(img)  # Convert image to array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Rescale the image\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the index of the highest predicted class\n",
    "\n",
    "# Manually define the class labels (use the folder names in your dataset)\n",
    "# Replace this path with the actual path to your 'train' directory\n",
    "train_dir = r\"C:\\Users\\Hp\\Videos\\back up\\wastes\\train\"\n",
    "class_labels = sorted(os.listdir(train_dir))  # Sort to ensure consistent order\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6609708,
     "sourceId": 10671487,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
